{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This python notebook is to just check all the api connections and get some checks done on the basic functioning of the langchain project"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b31b67f4c676ba8"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:56:50.296820200Z",
     "start_time": "2023-09-02T19:56:50.247793600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the dotenv library to use keys and ids for different APIs as they must remain a secret from the public\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "#this checks if the \".env\" file exists or not\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\nFurry pets are animals that are covered in soft, thick fur, such as cats, dogs, rabbits, and guinea pigs.'"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we import OpenAI's \"text-davinci-003\" from lang-chains large shelf of Large-Language-Models\n",
    "from langchain.llms import OpenAI as oa\n",
    "llm = oa (model_name = \"text-davinci-003\")\n",
    "#we test it out and we get a result as a normal ChatGPT response, this is also using the free grant I have got from OpenAI of $5 \n",
    "llm(\"Explain furry pets in a sentence\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:56:53.538532400Z",
     "start_time": "2023-09-02T19:56:51.784115Z"
    }
   },
   "id": "95665c5ceb608705"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "#import a schema or a structure from the lang-chain library. The Human Message is a normal prompt a user gives and the System Message is a feedback giver to the user (Maybe a role to play) before accepting the Human Messsage. The Ai message here could be considered as the output\n",
    "from langchain.schema import (AIMessage, HumanMessage, SystemMessage)\n",
    "#importing a chatbot model so that it keeps tack the state of the conversation, generate prompts to improve quality of responses, select the best response, and logging the conversation to fine tune the output \n",
    "from langchain.chat_models import ChatOpenAI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:56:58.622358100Z",
     "start_time": "2023-09-02T19:56:58.611488100Z"
    }
   },
   "id": "c50546996f367c56"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a Python script that splits a dataset into training and testing sets and trains a Linear Regression model using scikit-learn library:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LinearRegression\n",
      "\n",
      "# Load the dataset\n",
      "data = pd.read_csv('dataset.csv')  # Replace 'dataset.csv' with your dataset file\n",
      "\n",
      "# Split the dataset into features and target variable\n",
      "X = data.drop('target_variable', axis=1)  # Replace 'target_variable' with your target variable column name\n",
      "y = data['target_variable']\n",
      "\n",
      "# Split the dataset into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Adjust test_size as desired\n",
      "\n",
      "# Train the Linear Regression model\n",
      "model = LinearRegression()\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Evaluate the model\n",
      "train_score = model.score(X_train, y_train)\n",
      "test_score = model.score(X_test, y_test)\n",
      "\n",
      "print(\"Training score:\", train_score)\n",
      "print(\"Testing score:\", test_score)\n",
      "```\n",
      "\n",
      "Make sure to replace `'dataset.csv'` with the path to your dataset file and `'target_variable'` with the name of your target variable column. Adjust the `test_size` parameter in the `train_test_split` function to set the desired ratio of testing data.\n",
      "\n",
      "This script assumes that your dataset is in a CSV file format. If your dataset is in a different format, you may need to modify the code accordingly to load the data correctly.\n"
     ]
    }
   ],
   "source": [
    "#here we use gpt-3.5-turbo as the 4th generation has a really complicated relationship of money with my grandpa\n",
    "chat = ChatOpenAI (model_name = \"gpt-3.5-turbo\", temperature = 0.3)\n",
    "messages = [\n",
    "    SystemMessage(content = \"You are an expert on Data Science\"),\n",
    "    HumanMessage(content = \"Write a python Script to Split a dataset and train it in LinearRegression\")\n",
    "]\n",
    "response = chat(messages)\n",
    "print(response.content,end = \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:57:17.212252800Z",
     "start_time": "2023-09-02T19:57:00.450345400Z"
    }
   },
   "id": "faff3c2ddbd93bd9"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "PromptTemplate(input_variables=['concept'], output_parser=None, partial_variables={}, template=' You are an expert on AI that talks all the things about it like a teacher. Explain the concept of {concept} in a couple of lines in the most sensible way possible', template_format='f-string', validate_template=True)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PromptTemplate is very important as it makes everything very flexible \n",
    "from langchain import PromptTemplate\n",
    "template = ''' You are an expert on AI that talks all the things about it like a teacher. Explain the concept of {concept} in a couple of lines in the most sensible way possible'''\n",
    "prompt = PromptTemplate(input_variables = [\"concept\"], template= template)\n",
    "prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:57:28.249182200Z",
     "start_time": "2023-09-02T19:57:28.239535100Z"
    }
   },
   "id": "99d6d02d5be4a3f1"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "'.\\n\\nLinear regression is a predictive modeling technique that uses a linear equation to describe the relationships between input variables (x) and a continuous output variable (y). In linear regression, a dependent variable is predicted from one or more independent variables using a linear combination of the independent variables.'"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt.format(concept = \"Linear Regression\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:57:32.069015600Z",
     "start_time": "2023-09-02T19:57:30.765881300Z"
    }
   },
   "id": "4f441a16d3c371f2"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Linear regression is a statistical method used to identify the linear relationship between one or more independent variables and a continuous dependent variable. It attempts to find the \"best fit\" line that describes the relationship between the variables.\n"
     ]
    }
   ],
   "source": [
    "#now the chain part, it is a part that can be used as an agent or an llm, what it does is just like a prompt it executes if single but in a much lagrer number one chains output is used as another chains input\n",
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm = llm, prompt = prompt)\n",
    "print(chain.run(\"Linear Regression\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:57:38.856838200Z",
     "start_time": "2023-09-02T19:57:37.797455600Z"
    }
   },
   "id": "d7de05699805c3b3"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "#as seen over here the second chain is created over here... I can add another chain to this where the third chain produces questions to the topic\n",
    "second_prompt = PromptTemplate( input_variables = [\"another_concept\"], template = \"Turn the concept of {another_concept} into a very layman term in 500 words\")\n",
    "chain_two = LLMChain(llm = llm, prompt = second_prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:57:44.487050600Z",
     "start_time": "2023-09-02T19:57:44.478379100Z"
    }
   },
   "id": "19221d9c3f392748"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m\n",
      "\n",
      "Linear regression is a supervised machine learning algorithm used to predict continuous or quantitative values. It is a statistical technique that models the relationship between a dependent variable (the value we are trying to predict) and one or more independent variables (the factors that influence the value) by fitting a linear equation to the observed data.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m\n",
      "\n",
      "Linear regression is a powerful tool for making predictions about the world. Put simply, it is a way of using the relationships between different variables to guess the value of something we don’t already have. \n",
      "\n",
      "For example, let’s say you want to predict how much a house will cost based on its size. You could look at the prices of other houses and the sizes of those houses to determine the relationship between these two variables. This relationship can then be used to predict the price of a house based on its size. \n",
      "\n",
      "To do this, we start by defining the “dependent variable”, which is the value we’re trying to predict. In our example, the dependent variable is the price of the house. \n",
      "\n",
      "We then define the “independent variables”, which are the factors that influence the value of the dependent variable. In our example, the independent variable is the size of the house. \n",
      "\n",
      "Once we’ve defined the dependent and independent variables, we can plot them on a graph. We do this by plotting the independent variable (the size of the house) on the x-axis and the dependent variable (the price of the house) on the y-\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "Linear regression is a powerful tool for making predictions about the world. Put simply, it is a way of using the relationships between different variables to guess the value of something we don’t already have. \n",
      "\n",
      "For example, let’s say you want to predict how much a house will cost based on its size. You could look at the prices of other houses and the sizes of those houses to determine the relationship between these two variables. This relationship can then be used to predict the price of a house based on its size. \n",
      "\n",
      "To do this, we start by defining the “dependent variable”, which is the value we’re trying to predict. In our example, the dependent variable is the price of the house. \n",
      "\n",
      "We then define the “independent variables”, which are the factors that influence the value of the dependent variable. In our example, the independent variable is the size of the house. \n",
      "\n",
      "Once we’ve defined the dependent and independent variables, we can plot them on a graph. We do this by plotting the independent variable (the size of the house) on the x-axis and the dependent variable (the price of the house) on the y-\n"
     ]
    }
   ],
   "source": [
    "#simple sequential chain just puts the order of the chains linearly \n",
    "from langchain.chains import SimpleSequentialChain\n",
    "#verbose also prints the progress\n",
    "overall_chain = SimpleSequentialChain(chains = [chain, chain_two], verbose = True)\n",
    "explanation = overall_chain.run(\"Linear Regression\")\n",
    "print(explanation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:58:01.253417700Z",
     "start_time": "2023-09-02T19:57:55.658831100Z"
    }
   },
   "id": "1203e381582f6844"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='Linear regression is a powerful tool for making predictions about the world. Put simply, it is a way', metadata={}),\n Document(page_content='of using the relationships between different variables to guess the value of something we don’t', metadata={}),\n Document(page_content='already have.', metadata={}),\n Document(page_content='For example, let’s say you want to predict how much a house will cost based on its size. You could', metadata={}),\n Document(page_content='look at the prices of other houses and the sizes of those houses to determine the relationship', metadata={}),\n Document(page_content='between these two variables. This relationship can then be used to predict the price of a house', metadata={}),\n Document(page_content='based on its size.', metadata={}),\n Document(page_content='To do this, we start by defining the “dependent variable”, which is the value we’re trying to', metadata={}),\n Document(page_content='predict. In our example, the dependent variable is the price of the house.', metadata={}),\n Document(page_content='We then define the “independent variables”, which are the factors that influence the value of the', metadata={}),\n Document(page_content='dependent variable. In our example, the independent variable is the size of the house.', metadata={}),\n Document(page_content='Once we’ve defined the dependent and independent variables, we can plot them on a graph. We do this', metadata={}),\n Document(page_content='by plotting the independent variable (the size of the house) on the x-axis and the dependent', metadata={}),\n Document(page_content='variable (the price of the house) on the y-', metadata={})]"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this function splits the large corpus into smaller chunks (like 100 characters as mentioned below) over here we are gonna use it for embedding (tokenizaion and vectorization)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "texts = text_splitter.create_documents([explanation])\n",
    "texts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T20:22:25.826967600Z",
     "start_time": "2023-09-02T20:22:25.747834300Z"
    }
   },
   "id": "af4db0cdfea89bd5"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "#here we use OpenAIs embedding tool to convert this categorical data to numerical\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "#one of the best things OpenAI keeps working on is the model called \"ada\"/adaptive it is trained on a very large corpus... It basically figures out the relationship between different characters and calculates the similarity_score, useful in searching relevant topics according to custom prompts\n",
    "embeddings = OpenAIEmbeddings(model_name=\"ada\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:23:54.541894800Z",
     "start_time": "2023-09-02T19:23:54.531014300Z"
    }
   },
   "id": "9c3bd95c31d73b93"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "[-0.004647566956370373,\n 0.0064872289348079735,\n 0.025378162147569546,\n 0.03552942737912639,\n 0.02833385218622883,\n 0.013514636141025646,\n 0.010171649088832809,\n 0.010487602136239213,\n 0.056953080236966255,\n -0.009769063483850352,\n -0.04036045091362556,\n -0.027375800649710347,\n 0.026336213684088026,\n -0.02078155623137294,\n 0.022809770053766394,\n -0.011588341605011994,\n 0.014268846310816792,\n 0.022891305482870234,\n 0.011955254761269586,\n 0.04219501855755869,\n 0.024501647902800062,\n -0.016582436929041423,\n 0.04296961072198064,\n 0.007929401505412752,\n 0.01805009141671695,\n 0.0352440515146178,\n 0.0322272071101629,\n 0.0386685730645919,\n 0.02568392280067668,\n -0.03147299973433949,\n -0.0278038663091184,\n -0.010242993054959959,\n 0.01814181924012006,\n 0.024236654964244847,\n 0.0010739854814750987,\n 0.015624386323845519,\n 0.03196221603425284,\n 0.01175141432586483,\n -0.02521508942671671,\n -0.004887079840499993,\n 0.010925859258623955,\n 0.00017039805314606244,\n -0.0005978264405278497,\n -0.004122677276409578,\n -0.005019576309777601,\n -0.002209123233270011,\n -0.07709253611658196,\n 0.0022537133285148014,\n -0.042928844870073875,\n 0.03840358198868184,\n 0.0014166926325945059,\n 0.043621901605391984,\n -0.0009669691248307469,\n 0.023706669087134417,\n 0.047617178609673586,\n -0.04614952598464322,\n 0.03630402326883866,\n -0.0040207570587071995,\n -0.023421291359980664,\n -0.005320241231396391,\n -0.011680070359737681,\n -0.007674600961156806,\n 0.021036356775628887,\n 0.008744764178354356,\n -0.04590491597204138,\n 0.00906071722576076,\n -0.0327368119239651,\n -0.02988304024036304,\n 0.015277857956186464,\n -0.033205643435279916,\n 0.016327636384785474,\n 0.01933428653229595,\n 0.020842706871878242,\n 0.004084457194771186,\n -0.029251134145550233,\n 0.005228512942331992,\n 0.02660120662264324,\n 0.006772606196300438,\n 0.015868995405124774,\n -0.0015300789446375952,\n 0.007868249933584872,\n -0.01770356118641274,\n -0.0006656671785682532,\n -0.032859113204975705,\n -0.018916413267187165,\n 0.04508955423042236,\n -0.016613014111939228,\n -0.018457772287526465,\n -0.002965881734466619,\n -0.021219812422435102,\n 0.03479560106661121,\n 0.02888422098929264,\n -0.039300479159404704,\n -0.012638120964933584,\n 0.009733391966448067,\n -0.014758063542052724,\n 0.028028091533121694,\n 0.0013759244523812969,\n -0.011364117312331277,\n 0.005569946044163991,\n 0.0036691317954065765,\n -0.033389099082086135,\n -0.0355905780196317,\n -0.05026710799522574,\n 0.005126592724629614,\n 0.04439649749510425,\n -0.03332794844158084,\n -0.051571686036758116,\n -0.040666211566732696,\n 0.01598110801712642,\n 0.029760737096707283,\n 0.039769314396009836,\n 0.022789385265167855,\n -0.05911379332260505,\n 0.05479237087661777,\n -0.005987819309272773,\n -0.0047112670924343595,\n 0.022646697332913555,\n 0.019405631429745676,\n 0.0375882165217725,\n 0.022096328529849746,\n 0.019110061308292653,\n -0.006278292302253583,\n 0.007205767587196835,\n 0.018498540002078383,\n 0.012587160856082394,\n -0.018304891960972895,\n 0.003990180807131971,\n -0.017020694982748743,\n 0.045823380542937546,\n 0.020842706871878242,\n -0.014819216045203183,\n -0.0012644490978539983,\n -0.02262631254431502,\n -0.002308495585228217,\n -0.0024830340511757974,\n 0.005998011237910753,\n 0.046597976432649804,\n 0.05010403341172774,\n -0.020740786654175863,\n 0.006461748880382379,\n -0.009437822776317623,\n 0.009677335660447244,\n -0.041216582232441665,\n 0.02018022545681278,\n 0.08365620707731188,\n -0.031208004933139116,\n 0.008413523470821627,\n -0.011404885026883197,\n -0.02497048127676003,\n -0.0036079797579174075,\n 0.002531446294282814,\n -0.00590118721735801,\n 0.03960623981251184,\n 0.04472264293680992,\n 0.015124976698310318,\n -0.029169598716446393,\n 0.04036045091362556,\n 0.004922751823563568,\n -0.03206413625195522,\n 0.02177018308814407,\n 0.0012982102398171045,\n -0.029556896661302526,\n 0.04749487360337267,\n -0.014136349841539185,\n 0.0017479336893732023,\n -0.05189783147846379,\n 0.024155117672495847,\n 0.05597464391184923,\n -0.00642098070016917,\n 0.01496190490878006,\n 0.009290037715591112,\n -0.03383754953009273,\n -0.03277757777587187,\n 0.026947734990302296,\n -0.005687154387653983,\n 0.03363370909468797,\n -0.0020345845344917858,\n -0.016286868670233556,\n 0.04924790209291164,\n 0.03775129110527049,\n 0.04127773287294697,\n 0.021117892204732727,\n 0.03139146057994534,\n 0.01234255177480314,\n -0.024420110611051062,\n 0.08536846971494408,\n 0.007103846903833168,\n -0.017774906083862466,\n -0.01069144257164397,\n 0.00802113026013844,\n -0.01801951423381914,\n 0.01758125618011182,\n 0.035121746508316884,\n -0.02929190372274731,\n -0.025276241929867167,\n -0.00013130204807066184,\n -0.038607422424086595,\n -0.040625441989535625,\n 0.011680070359737681,\n 0.033552173665584134,\n 0.028598845124784045,\n -0.03157491995204187,\n 0.01330060331132162,\n -0.025235474215315246,\n -0.010344913272662336,\n 0.05630078935355491,\n 0.016684359009388958,\n 0.011863526937866476,\n -0.017907401621817497,\n -0.003768504147364782,\n -0.05984761963512024,\n 0.0463125968428509,\n -0.028639612839335964,\n -0.014533839249372007,\n -0.029108446213295936,\n -0.016409173676534473,\n -0.014187309950390374,\n 0.05650462978895966,\n 0.049003295805600124,\n -0.06086682181214402,\n -0.015614194860868827,\n 0.019395439035446407,\n -0.02240208918295688,\n -0.015328818065037653,\n -0.0644544142203258,\n -0.017346840424454415,\n -0.02550046715387046,\n -0.015053632732183169,\n 0.029067678498744014,\n 0.042928844870073875,\n -0.03318525864668138,\n -0.032329127327865276,\n 0.033735629312390346,\n 0.001814181924012006,\n -0.015298241813462423,\n 0.03571288302593261,\n 0.017346840424454415,\n -0.007944690096861657,\n -0.01871257283178241,\n 0.00347038732432081,\n -0.03956547396060508,\n -0.01009011272840639,\n 0.047576409032476515,\n -0.024827793344505734,\n -0.013535019998301607,\n 0.01279100129148715,\n -0.027926171315419315,\n 0.023441676148579203,\n 0.008367659559120073,\n -0.011975638618545547,\n -0.02574507530382714,\n 0.06800124822718144,\n -0.0448857137950176,\n 0.0026601206156981953,\n 0.03345025344788175,\n -0.0440295824762015,\n -0.018253931852121708,\n 0.010569138496665633,\n 0.01827431477807509,\n -0.004076813364708024,\n 0.04439649749510425,\n -0.002293207459440602,\n -0.07387185872730294,\n -0.004127773473559212,\n 0.010956435510199185,\n -0.018987758164636895,\n 0.0327368119239651,\n 0.05234628192647038,\n -0.0006487866075867001,\n 0.020659251225072024,\n -0.013749052828005632,\n 0.01979292751195665,\n 0.01712261520045112,\n -0.0013147722984768054,\n -0.006043875615273597,\n 0.022075943741251207,\n -0.030209185682068714,\n -0.0214440376464384,\n 0.04366267118258906,\n -0.05825766200378895,\n 0.0298015048112592,\n -0.018457772287526465,\n -0.016694549541043067,\n 0.02037387349791827,\n -0.017285687921303958,\n 0.06506593552654007,\n -0.0406050609262274,\n 0.030392643191520092,\n -0.015818035296273583,\n 0.043091915728281555,\n 0.013198683093619242,\n -0.016093220629128067,\n -0.18508732396377653,\n -0.012994841726891908,\n -0.045660309684729866,\n 0.020455410789667266,\n 0.011883910795142437,\n 0.026010068242382355,\n -0.015563234752017638,\n 0.005279473051183182,\n 0.0630275311724925,\n -0.016714934329641606,\n 0.015705922684271935,\n 0.00616108395876359,\n -0.03830166177097946,\n 0.00986079223857604,\n 0.005009384381139621,\n 0.03318525864668138,\n 0.033756014100988885,\n 0.007119135029620782,\n -0.017968554124967954,\n 0.0018447579427565905,\n 0.005406873323311154,\n 0.010457025884663984,\n -0.04215424898036161,\n 0.006711453693149979,\n -0.03379677995289565,\n -0.014329998813967251,\n -0.027049655208004675,\n -0.01813162684582079,\n -0.030351873614323014,\n 0.01452364685507274,\n 0.02435895997054576,\n -0.006043875615273597,\n 0.02609160553413135,\n 0.044314958340710094,\n -0.03224759189876144,\n 0.012964266406639257,\n 0.000504824160383704,\n 0.01062009860551682,\n 0.023849357019388714,\n 0.03726207108006683,\n -0.015879187799424044,\n -0.029740352308108745,\n 0.024093967031990546,\n 0.02435895997054576,\n -0.005636194278802795,\n -0.008235163089842465,\n -0.05308010823898557,\n -0.007266919624686004,\n 0.07554335178773806,\n 0.011690261822714371,\n 0.0355905780196317,\n 0.014238270059241564,\n -0.004122677276409578,\n 0.0011153905699166898,\n -0.10885091171543004,\n 0.03485675170711651,\n 0.043091915728281555,\n -0.0028868934726150185,\n 0.01170045421701364,\n 0.007149711281196011,\n 0.015868995405124774,\n 0.016786279227091333,\n 0.0025097881548888003,\n -0.03985084982511367,\n -0.01547150599729195,\n 0.07293418825409267,\n 0.018600460219780762,\n 0.018590267825481493,\n -0.008836492933080043,\n -0.010380585721387201,\n 0.01820297174327052,\n -0.011160275945603941,\n 0.009300230109890381,\n 0.0019530482904806898,\n 0.01933428653229595,\n -0.020485986109919918,\n 0.021219812422435102,\n -0.018783917729232137,\n -0.034041389965497486,\n -0.008678516409376842,\n 0.0026244486326346206,\n -0.005636194278802795,\n 0.05952147419341457,\n -0.013657324073279945,\n 0.1273596441118077,\n -0.050389413001526655,\n 0.0362224841144445,\n 0.05699384981416333,\n -0.015135169092609587,\n -0.023645516583983957,\n -0.06461749252911411,\n 0.007521720634603239,\n 0.047046423155366085,\n 0.0051214965274799795,\n -0.008439003525247221,\n 0.018488347607779114,\n 0.05250935278467806,\n 0.06526978341252546,\n 0.024134734746542468,\n 0.036161333473939204,\n 0.005065440221479155,\n 0.033348333230179376,\n 0.039932385254217516,\n -0.0032869307461920135,\n 0.05548542761193588,\n 0.02452203082875344,\n -0.04782101904507834,\n -0.029597664375854444,\n -0.04105350764894367,\n -0.017560873254158442,\n -0.030229570470667252,\n -0.04586415012013462,\n 0.02368628429853588,\n -0.05723845610147485,\n -0.05650462978895966,\n 0.037567835458464274,\n 0.028700765342486424,\n -0.008887453041931233,\n -0.0005975079282059976,\n -0.013127338196169515,\n -0.022259399388057426,\n 0.010237896857810324,\n -0.009096389674485625,\n 0.018325274886926278,\n -0.026438133901790405,\n 0.002063886736779606,\n -0.044478032924208086,\n -0.0026346405612726006,\n -0.004448822252453962,\n 0.013657324073279945,\n 0.008275930804394385,\n 0.06779740034119605,\n -0.019069293593740735,\n -0.009254366198188826,\n -0.015451122140015991,\n -0.024787023767308656,\n -0.03693592936365147,\n -0.06241600986627823,\n -0.026580821834044702,\n -0.029434591655001608,\n -0.02132173264013748,\n 0.02299322570057261,\n -0.05736076110777577,\n -0.018865453158335977,\n 0.011731030468588869,\n 0.04280653986377296,\n -0.00966204706899834,\n 0.07570642264594574,\n 0.009376670273167164,\n -0.013066186624341634,\n 0.00537120134024758,\n 0.028537692621633585,\n 0.023788204516238257,\n 0.0017288236485540063,\n 0.009208502286487272,\n 0.038750108493695735,\n 0.011822758291991978,\n -0.01013088044295831,\n 0.017683178260459356,\n 0.03881126285949135,\n 0.018315084355272165,\n -0.02047579371562065,\n -0.003508607405959202,\n 0.026906967275750378,\n -0.016582436929041423,\n 0.03267565755816949,\n -0.0576053711203776,\n -0.0213013497141841,\n 0.0341636949717984,\n -0.009183022232061678,\n -0.002088092741917792,\n -0.06363905247870677,\n 0.007582872672092408,\n -0.03504021107921304,\n -0.04195040854495685,\n -0.009386862667466434,\n 0.02462395104645582,\n 0.025846995521529515,\n 0.022830154842364933,\n 0.0033429868193621923,\n 0.02462395104645582,\n 0.03487713649571505,\n 0.023788204516238257,\n 0.0176220257573089,\n 0.009774159680999987,\n 0.02713119249975367,\n 0.02136250221733456,\n -0.019629854791103813,\n -0.008296314661670344,\n -0.01228140020297526,\n 0.008301410858819979,\n -0.01987446480370565,\n 0.016847429867596637,\n -0.014921136262905562,\n -0.051408615178550436,\n -0.017785098478161735,\n -0.001091184564778504,\n 0.016776086832792067,\n -0.014513455392096048,\n -0.008714187926779127,\n 0.0025059662398572193,\n -0.010579329959642322,\n -0.04305114615108448,\n 0.0037710522459395994,\n -0.006665589781448425,\n -0.017438568247857524,\n -0.11667839486578557,\n -0.03518289714882218,\n -0.055893108482745396,\n 0.04806562905768018,\n 0.04223578440946545,\n 0.011139892088327982,\n 0.04407035205339857,\n -0.01491094479992887,\n 0.019446399144297594,\n 0.005569946044163991,\n -0.020088497633409672,\n 0.01394270086911112,\n 0.006359828662680001,\n 0.036507863704243415,\n 0.014513455392096048,\n 3.089460018803434e-05,\n -0.0044921385312419885,\n -0.01184314214926794,\n 0.021566342652739316,\n 0.02071021133392321,\n -0.003488223315852597,\n -0.04786178862227542,\n -0.008133241940817508,\n -0.010599714748240861,\n 0.001304580253423503,\n 0.007720464872858361,\n -0.025908148024679976,\n 0.013025417978467136,\n 0.010752595074794428,\n -0.012587160856082394,\n -0.0067063579616616345,\n -0.03432676583000608,\n 0.05026710799522574,\n 0.009188117497888733,\n 0.030902244280031983,\n -0.013585980107152796,\n -0.033246413012476994,\n 0.008444099722396856,\n 0.03137107951663711,\n 0.022096328529849746,\n -0.0031926543585527978,\n 0.045538004678428945,\n -0.018946988587439817,\n 0.00010972360951668809,\n -0.024909328773609574,\n -0.0057024425134415985,\n 0.021709030584993613,\n -0.01923236631459357,\n -0.007246535301748755,\n -0.02933267143729923,\n 7.401167416968678e-05,\n -0.005931763468933238,\n 0.005205580986481215,\n 0.008123050477840817,\n -0.03133030993944003,\n 0.0005016391535805047,\n -0.00964166321172238,\n 0.018396619784376005,\n -0.02998496045806542,\n 0.06033683593503359,\n 0.0020435026466730016,\n 0.017978746519267223,\n -0.023462060937177738,\n 0.021790566014097453,\n -0.04663874228455657,\n 0.013973277120686349,\n 0.022850537768318312,\n 0.030290722973817713,\n 0.006522901383532838,\n -0.015767075187422395,\n 0.021179044707883184,\n -0.023747436801686336,\n 0.01228140020297526,\n -0.02191287102039837,\n -0.0176220257573089,\n 0.0008370206959202956,\n -0.04195040854495685,\n 0.03347063823648029,\n -0.03292026757077132,\n 0.02733503293515843,\n -0.01394270086911112,\n -0.06824585078920264,\n -0.0012542570528006958,\n -0.019211981525995032,\n -0.038077436546976165,\n -0.024868561059057655,\n -0.04264346528027496,\n -0.025194706500763327,\n 0.003521347433171999,\n -0.005177552833480803,\n -0.006568765295234392,\n -0.031309925150841494,\n 0.018957180981739086,\n 0.01335156342017281,\n 0.039810080247916595,\n -0.03936163352520032,\n 0.035468276738621095,\n -0.01121123605445513,\n 0.008286123198693655,\n -0.00047679603648712266,\n -0.015726307472870474,\n 0.07623640479776586,\n 0.021199429496481723,\n -0.042031943974060695,\n 0.022504009400659258,\n -0.03259412212906565,\n 0.006864334485364837,\n -0.04790255447418219,\n -0.02670312684034562,\n 0.032186441258256135,\n -0.02947535936955353,\n -0.03367447867188505,\n 0.03803666696977909,\n 0.0037736003445144168,\n -0.0033633709094687972,\n 0.04398881289900442,\n -0.0170818474858992,\n -0.028537692621633585,\n 0.044111117905305336,\n -0.007914113845286426,\n -0.00639040491425523,\n -0.05006326755982098,\n 0.03326679780107553,\n -0.015889380193723313,\n 0.04614952598464322,\n -0.01869218804318387,\n -0.008000746402862479,\n 0.015420545888440761,\n -0.0009618731023040958,\n 0.07028426259383085,\n -0.03204375146335668,\n -0.021036356775628887,\n 0.00665030165566081,\n 0.033715244523791814,\n 0.03196221603425284,\n -0.0341636949717984,\n 0.004107389150621963,\n -0.020995589061076965,\n -0.016490709105638313,\n -0.015145361486908857,\n 0.032166056469657596,\n 0.05079709387233617,\n -0.006563669098084758,\n 0.0010803554950814974,\n 0.010457025884663984,\n 0.06840892909799096,\n 0.06584053514154264,\n -0.025867380310128054,\n 0.027987321955924616,\n 0.015746690398823857,\n 0.011415077421182467,\n 0.028476540118483128,\n 0.02772233088001456,\n -0.01493132865720483,\n -0.003995277004281605,\n 0.03051494633517585,\n -0.01828450717237436,\n -0.05165322519115227,\n -0.025520850079823843,\n 0.030209185682068714,\n 0.011333541060756047,\n 0.07827481660239405,\n -0.002848673158145982,\n 0.04696488772626224,\n 0.04219501855755869,\n -0.021117892204732727,\n 0.024338575181947226,\n 0.04590491597204138,\n 0.0022817414815152134,\n -0.001560655079797502,\n 0.007664409032518827,\n -0.03169722123305247,\n 0.018926605661486434,\n 0.02837461990078075,\n -0.004846311660286784,\n 0.030290722973817713,\n -0.021219812422435102,\n -0.017866633907265575,\n -0.0064056925743815555,\n -0.03954508917200654,\n 0.010834131435220848,\n 0.00642098070016917,\n -0.049329441247305796,\n -0.030249953396620635,\n 0.017968554124967954,\n 0.02841538761533267,\n -0.10322491122791039,\n -0.01879410826088625,\n -0.0007236343256695453,\n -0.02517432171216479,\n 0.02576546009242568,\n 0.01386116544000728,\n 0.035101361719718345,\n -0.02246324168610734,\n 0.01914063849119046,\n -0.023747436801686336,\n 0.0223001689652545,\n 0.03489752128431359,\n -0.0638836624913086,\n -0.024807408555907195,\n -0.004120129177834761,\n 0.03864818827599336,\n 0.07501336218533732,\n -0.04663874228455657,\n 0.027620408799667026,\n 0.0009644211426712519,\n 0.03190106166845723,\n -0.027987321955924616,\n -0.028456157192529745,\n 0.02152557307554224,\n 0.022198248747552125,\n 0.03687477499785585,\n 0.033898700170598026,\n 0.039524704383408,\n 0.045660309684729866,\n -0.040340066125027024,\n 0.003075446015062805,\n -0.015726307472870474,\n 0.03381716474149419,\n -0.012892921509189529,\n 0.03779205695717726,\n -0.020567523401668914,\n 0.07260804653767731,\n -0.02391050952253917,\n -0.012495432101356707,\n 0.001079718470437793,\n 0.016174756058231907,\n 0.004122677276409578,\n -0.024787023767308656,\n -0.012587160856082394,\n -0.06327214118509433,\n -0.038260892193782384,\n -0.012475048244080748,\n -0.005518985935312802,\n 0.013188490699319974,\n -0.0298015048112592,\n 0.0008784258425695479,\n -0.04215424898036161,\n 0.04439649749510425,\n -0.044314958340710094,\n 0.022320551891207883,\n -0.021280964925585562,\n 0.04892176037649628,\n 0.04001392068332135,\n -0.040808901361632156,\n 0.01869218804318387,\n -0.01066086632006874,\n -0.03903548808349465,\n 0.010497794530538482,\n 0.015726307472870474,\n 0.023298988216324902,\n 0.04513032380761944,\n -0.0011198496260072979,\n -0.01115008448262725,\n 0.03901510329489611,\n 0.006186564013189184,\n -0.026478901616342324,\n 0.009305326307040016,\n -0.016704741935342337,\n -0.03840358198868184,\n 0.02020061024541132,\n 0.0030219378076367983,\n -0.030983779709135822,\n 0.03552942737912639,\n 0.02138288514328794,\n -0.03298141821127663,\n -0.039402399377107086,\n 0.025908148024679976,\n 0.010212416803384729,\n -0.07069194346464035,\n -0.014798832187927222,\n 0.03367447867188505,\n 0.023380523645428742,\n 0.03261450691766419,\n 0.023033995277769687,\n 0.06049990679324127,\n -0.015787459976020934,\n -0.008688707872353534,\n -0.04753564318056975,\n 0.017387608139006337,\n 0.005376297537397214,\n -0.005753402622292787,\n 0.017479335962409442,\n -0.030148033178918256,\n -0.03279796256447041,\n 0.039117023512598485,\n 0.011832950686291248,\n 0.03483637064380828,\n 0.03587595760943061,\n 0.009315517770016707,\n 0.0005503697925940509,\n -0.007272015821835638,\n -0.033919084959196565,\n 0.04305114615108448,\n 0.012556584604507166,\n 0.001898266150182597,\n -0.0016498353867024052,\n 0.005513889738163167,\n 0.03991200046561898,\n 0.003646199839555799,\n 0.010885091544072035,\n -0.03795513154067525,\n -0.032308746264557056,\n -0.04119619744384313,\n -0.030779939273731065,\n -0.030779939273731065,\n -0.04578261096574047,\n -0.041216582232441665,\n -0.04089043679073599,\n 0.01810105152556814,\n 0.01439115038579513,\n 0.010772978932070389,\n -0.06730818776657302,\n -0.021505190149588856,\n 0.0213013497141841,\n 0.045008018801318515,\n 0.015593811003592868,\n -0.005396681394673174,\n 0.024664720623652898,\n 0.010023864959428877,\n -0.030107265464366338,\n -0.03709900022185915,\n 0.011119508231052021,\n -0.021790566014097453,\n -0.012536200747231205,\n 0.027987321955924616,\n -0.00827083460724475,\n 0.03159530101535009,\n 0.017978746519267223,\n 0.036487478915644876,\n 0.029964577532112038,\n -0.017968554124967954,\n -0.01552246610614314,\n -0.03345025344788175,\n 0.010528369850791133,\n 0.03732322544586244,\n 0.0046501150549451906,\n -0.004316325783176355,\n 0.012770617434211191,\n -0.015237089310311966,\n 0.02456280040595052,\n 0.058543037868297544,\n -0.016184948452531177,\n -0.030596483626924846,\n -0.01394270086911112,\n 0.04696488772626224,\n 0.010966627904498455,\n -0.016195140846830446,\n -0.0031620783398082133,\n -0.01065067485709205,\n 0.05511851631832344,\n -0.01651109389423685,\n 0.03051494633517585,\n -0.04773948361597451,\n 0.006018395560848002,\n -0.005829842785569571,\n 0.047576409032476515,\n -0.003029581870530606,\n -0.036140948685340665,\n -0.02368628429853588,\n 0.0020040085157472013,\n -0.032349512116463815,\n 0.007124231226770417,\n 0.022320551891207883,\n -0.006604437278297967,\n -0.011486421387309615,\n -0.010885091544072035,\n 0.00993213620470319,\n 0.0375882165217725,\n 0.014707103433201535,\n 0.007205767587196835,\n -0.013647132610303253,\n -0.02507240149446241,\n 0.041400037879247883,\n -0.027865018812268858,\n 0.011985831012844816,\n -0.03149338079764771,\n -0.09246212282749411,\n -0.037690136739474876,\n -0.04790255447418219,\n -0.03605941325623682,\n -0.15385893051674857,\n 0.024216270175646308,\n -0.016195140846830446,\n -0.017153192383348927,\n 0.046231061413747054,\n 0.011557765353436764,\n 0.0488809907992992,\n -0.022667082121512094,\n 0.012057174978971965,\n -0.023543596366281578,\n 0.03766975567616665,\n -0.0069866385603431745,\n -0.02827269968307837,\n -0.01234255177480314,\n -0.04912560081190104,\n 0.01014107283725758,\n -0.010956435510199185,\n -0.031228389721737655,\n -0.015604002466569558,\n -0.004856503588924765,\n -0.052468586932771295,\n -0.01284196140033834,\n -0.019884657198004918,\n -0.040299300273120266,\n 0.030678019056028686,\n -0.02124019721103364,\n 0.03145261494574095,\n -0.052753962797279896,\n 0.01923236631459357,\n 0.04835100492218877,\n -0.02009869002770894,\n 0.02134211742873602,\n 0.02462395104645582,\n -0.00025862283763732454,\n 0.016083028234828798,\n 0.029434591655001608,\n -0.045823380542937546,\n 0.012444471992505517,\n -0.015685539758318556,\n 0.004685787038008765,\n -0.025846995521529515,\n 0.014533839249372007,\n -0.013749052828005632,\n 0.028659997627934503,\n 0.039993539620013126,\n 0.003913740643855187,\n -0.12295668623671659,\n -0.05389546998060459,\n 0.00028123642668540253,\n 0.06082605223494694,\n 0.04076813178443508,\n 0.012189671448249572,\n 0.058379967010089864,\n 0.006624821601235216,\n 0.016776086832792067,\n 0.034224845612303705,\n 0.0028665093825084136,\n 0.011934870903993627,\n 0.04215424898036161,\n 0.054221615422310264,\n -0.0364467093384478,\n 0.000265789102944523,\n 0.08553154057315177,\n -0.04953328168271055,\n -0.0047112670924343595,\n 0.0036665839296624037,\n 0.013800012936856822,\n 0.005253992996757587,\n 0.007379031771026362,\n -0.00139758259177531,\n -0.030311105899771092,\n -0.0058247470540812255,\n -0.004176185483835584,\n -0.006833758233789607,\n 0.03198260082285138,\n -0.02138288514328794,\n -0.008464483579672817,\n 0.035447891950022556,\n 0.01873295762038095,\n 0.011058355727901563,\n -0.010997203224751105,\n -0.047046423155366085,\n -0.0256635398747233,\n 0.04329575616368631,\n -0.0027110807245493843,\n -0.029026910784192096,\n -0.00833198711039521,\n 0.04663874228455657,\n 0.02360474886943204,\n -0.026010068242382355,\n 0.03532558694372164,\n 0.03198260082285138,\n 0.016898389976447825,\n -0.013932509406134429,\n -0.04533416424302419,\n -0.046190295561840296,\n 0.0061101238499124,\n -0.1305395668250509,\n 0.02947535936955353,\n -0.06425057378492104,\n 0.022911690271468773,\n 0.033164873858082845,\n 0.011384501169607236,\n -0.022850537768318312,\n -0.040176995266819344,\n 0.02674389455489754,\n -0.03243104754556766,\n -0.013912125548858468,\n 0.03605941325623682,\n -0.03709900022185915,\n -0.030351873614323014,\n 0.00971300717784953,\n -0.03660978392194579,\n -0.019558511756299243,\n 0.005022124408352418,\n -0.03722130522816006,\n -0.04264346528027496,\n 0.0033378908550432025,\n -0.0019708843984277994,\n 0.003350630882256,\n ...]"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is just the numerical representation of the corpus we generated above and split into different parts\n",
    "query_result = embeddings.embed_query(texts[0].page_content)\n",
    "query_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:24:16.409356Z",
     "start_time": "2023-09-02T19:24:15.677041800Z"
    }
   },
   "id": "dbb46afc87c1f384"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "#here we use pinecone a vector storing tool (obv the free version coz we broke)\n",
    "import os\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "pinecone.init(\tapi_key= os.getenv(\"PINECONE_API_KEY\") ,      \n",
    "\tenvironment=os.getenv(\"PINECONE_ENV\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:26:06.724980300Z",
     "start_time": "2023-09-02T19:26:05.112059400Z"
    }
   },
   "id": "6563fa4f590ecd1d"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "#this is the indexname I gave on the website\n",
    "index_name = 'langchain-test2'\n",
    "search = Pinecone.from_documents(texts,embeddings,index_name=index_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T19:31:55.554960900Z",
     "start_time": "2023-09-02T19:31:47.435243800Z"
    }
   },
   "id": "29fe6baad91b8888"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='would look something like this:', metadata={}),\n Document(page_content='Linear regression works by finding a line that best fits the data points. It looks at the input', metadata={}),\n Document(page_content='The equation that it comes up with is called a linear regression equation, which is used to predict', metadata={}),\n Document(page_content='example, this would be the price.', metadata={})]"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now time for a custom query and results\n",
    "query = \"How does Linear Regression work ?\"\n",
    "result = search.similarity_search(query, include_scores = True)\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T20:33:23.336909300Z",
     "start_time": "2023-09-02T20:33:19.936089Z"
    }
   },
   "id": "99dc6bc48ab3e9f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ef9156f64bf3bae7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "71b9983de3820d27"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
